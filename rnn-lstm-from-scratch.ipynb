{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4cbf8aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:04.750874Z",
     "iopub.status.busy": "2025-07-22T16:38:04.749728Z",
     "iopub.status.idle": "2025-07-22T16:38:18.153543Z",
     "shell.execute_reply": "2025-07-22T16:38:18.152848Z"
    },
    "papermill": {
     "duration": 13.415056,
     "end_time": "2025-07-22T16:38:18.155189",
     "exception": false,
     "start_time": "2025-07-22T16:38:04.740133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c60703b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:18.171260Z",
     "iopub.status.busy": "2025-07-22T16:38:18.170829Z",
     "iopub.status.idle": "2025-07-22T16:38:18.610460Z",
     "shell.execute_reply": "2025-07-22T16:38:18.609518Z"
    },
    "papermill": {
     "duration": 0.449354,
     "end_time": "2025-07-22T16:38:18.612242",
     "exception": false,
     "start_time": "2025-07-22T16:38:18.162888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests, tarfile, os\n",
    "\n",
    "url = \"http://files.fast.ai/data/examples/human_numbers.tgz\"\n",
    "filename = \"human_numbers.tgz\"\n",
    "folder = \"human_numbers\"\n",
    "\n",
    "# Download\n",
    "response = requests.get(url)\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Extract\n",
    "with tarfile.open(filename, \"r:gz\") as tar:\n",
    "    tar.extractall()\n",
    "\n",
    "# Read data\n",
    "train_path = os.path.join(folder, \"train.txt\")\n",
    "valid_path = os.path.join(folder, \"valid.txt\")\n",
    "\n",
    "with open(train_path) as f:\n",
    "    train_lines = f.read().splitlines()\n",
    "\n",
    "with open(valid_path) as f:\n",
    "    valid_lines = f.read().splitlines()\n",
    "\n",
    "lines = train_lines + valid_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e159206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:18.627532Z",
     "iopub.status.busy": "2025-07-22T16:38:18.627224Z",
     "iopub.status.idle": "2025-07-22T16:38:18.631835Z",
     "shell.execute_reply": "2025-07-22T16:38:18.631035Z"
    },
    "papermill": {
     "duration": 0.013908,
     "end_time": "2025-07-22T16:38:18.633277",
     "exception": false,
     "start_time": "2025-07-22T16:38:18.619369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7999 1999 9998\n"
     ]
    }
   ],
   "source": [
    "print(len(train_lines), len(valid_lines), len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0bf867e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:18.650025Z",
     "iopub.status.busy": "2025-07-22T16:38:18.649124Z",
     "iopub.status.idle": "2025-07-22T16:38:18.656064Z",
     "shell.execute_reply": "2025-07-22T16:38:18.655218Z"
    },
    "papermill": {
     "duration": 0.016173,
     "end_time": "2025-07-22T16:38:18.657367",
     "exception": false,
     "start_time": "2025-07-22T16:38:18.641194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo\n"
     ]
    }
   ],
   "source": [
    "text = ' . '.join([l.strip() for l in lines])\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "530104f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:18.672608Z",
     "iopub.status.busy": "2025-07-22T16:38:18.672292Z",
     "iopub.status.idle": "2025-07-22T16:38:18.683407Z",
     "shell.execute_reply": "2025-07-22T16:38:18.682664Z"
    },
    "papermill": {
     "duration": 0.020299,
     "end_time": "2025-07-22T16:38:18.684725",
     "exception": false,
     "start_time": "2025-07-22T16:38:18.664426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text.split(' ')\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e412a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:18.700379Z",
     "iopub.status.busy": "2025-07-22T16:38:18.700078Z",
     "iopub.status.idle": "2025-07-22T16:38:18.709186Z",
     "shell.execute_reply": "2025-07-22T16:38:18.708379Z"
    },
    "papermill": {
     "duration": 0.018354,
     "end_time": "2025-07-22T16:38:18.710420",
     "exception": false,
     "start_time": "2025-07-22T16:38:18.692066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " '.',\n",
       " 'two',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'eleven',\n",
       " 'twelve',\n",
       " 'thirteen',\n",
       " 'fourteen',\n",
       " 'fifteen',\n",
       " 'sixteen',\n",
       " 'seventeen',\n",
       " 'eighteen',\n",
       " 'nineteen',\n",
       " 'twenty',\n",
       " 'thirty',\n",
       " 'forty',\n",
       " 'fifty',\n",
       " 'sixty',\n",
       " 'seventy',\n",
       " 'eighty',\n",
       " 'ninety',\n",
       " 'hundred',\n",
       " 'thousand']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(dict.fromkeys(tokens))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004b9108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:18.726588Z",
     "iopub.status.busy": "2025-07-22T16:38:18.725914Z",
     "iopub.status.idle": "2025-07-22T16:38:18.735476Z",
     "shell.execute_reply": "2025-07-22T16:38:18.734747Z"
    },
    "papermill": {
     "duration": 0.019147,
     "end_time": "2025-07-22T16:38:18.736904",
     "exception": false,
     "start_time": "2025-07-22T16:38:18.717757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 1, 3, 1, 4, 1, 5, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = {w:i for i,w in enumerate(vocab)}\n",
    "nums = [word2idx[i] for i in tokens]\n",
    "nums[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68551f54",
   "metadata": {
    "papermill": {
     "duration": 0.007192,
     "end_time": "2025-07-22T16:38:18.751481",
     "exception": false,
     "start_time": "2025-07-22T16:38:18.744289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction based on the previous 3 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06672915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:18.767498Z",
     "iopub.status.busy": "2025-07-22T16:38:18.767184Z",
     "iopub.status.idle": "2025-07-22T16:38:18.788994Z",
     "shell.execute_reply": "2025-07-22T16:38:18.788005Z"
    },
    "papermill": {
     "duration": 0.032234,
     "end_time": "2025-07-22T16:38:18.791167",
     "exception": false,
     "start_time": "2025-07-22T16:38:18.758933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['one', '.', 'two'], '.'),\n",
       " (['.', 'three', '.'], 'four'),\n",
       " (['four', '.', 'five'], '.'),\n",
       " (['.', 'six', '.'], 'seven'),\n",
       " (['seven', '.', 'eight'], '.'),\n",
       " (['.', 'nine', '.'], 'ten'),\n",
       " (['ten', '.', 'eleven'], '.'),\n",
       " (['.', 'twelve', '.'], 'thirteen'),\n",
       " (['thirteen', '.', 'fourteen'], '.'),\n",
       " (['.', 'fifteen', '.'], 'sixteen')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_pairs = [(tokens[i:i+3], tokens[i+3]) for i in range(0, len(tokens)-4, 3)]\n",
    "sequence_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa206170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:18.808180Z",
     "iopub.status.busy": "2025-07-22T16:38:18.807874Z",
     "iopub.status.idle": "2025-07-22T16:38:19.257103Z",
     "shell.execute_reply": "2025-07-22T16:38:19.256244Z"
    },
    "papermill": {
     "duration": 0.459011,
     "end_time": "2025-07-22T16:38:19.258542",
     "exception": false,
     "start_time": "2025-07-22T16:38:18.799531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0, 1, 2]), tensor(1)),\n",
       " (tensor([1, 3, 1]), tensor(4)),\n",
       " (tensor([4, 1, 5]), tensor(1)),\n",
       " (tensor([1, 6, 1]), tensor(7)),\n",
       " (tensor([7, 1, 8]), tensor(1)),\n",
       " (tensor([1, 9, 1]), tensor(10)),\n",
       " (tensor([10,  1, 11]), tensor(1)),\n",
       " (tensor([ 1, 12,  1]), tensor(13)),\n",
       " (tensor([13,  1, 14]), tensor(1)),\n",
       " (tensor([ 1, 15,  1]), tensor(16))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = [(torch.tensor(nums[i:i+3]), torch.tensor(nums[i+3])) for i in range(0, len(nums)-4, 3)]\n",
    "seqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1440ee5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:19.275257Z",
     "iopub.status.busy": "2025-07-22T16:38:19.274946Z",
     "iopub.status.idle": "2025-07-22T16:38:19.347366Z",
     "shell.execute_reply": "2025-07-22T16:38:19.346605Z"
    },
    "papermill": {
     "duration": 0.082776,
     "end_time": "2025-07-22T16:38:19.349019",
     "exception": false,
     "start_time": "2025-07-22T16:38:19.266243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cut = int(len(seqs) * 0.8)\n",
    "train_seqs = seqs[:cut]\n",
    "valid_seqs = seqs[cut:]\n",
    "\n",
    "# Unzipping\n",
    "x_train, y_train = zip(*train_seqs)\n",
    "x_valid, y_valid = zip(*valid_seqs)\n",
    "\n",
    "# Stacking\n",
    "x_train = torch.stack(x_train)\n",
    "y_train = torch.stack(y_train)\n",
    "x_valid = torch.stack(x_valid)\n",
    "y_valid = torch.stack(y_valid)\n",
    "\n",
    "# Wrap into dataset\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "\n",
    "# Create DataLoaders\n",
    "bs = 64\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dffc1ba",
   "metadata": {
    "papermill": {
     "duration": 0.007322,
     "end_time": "2025-07-22T16:38:19.363874",
     "exception": false,
     "start_time": "2025-07-22T16:38:19.356552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Unrolled RNN with no inter-sequence memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adcc566e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:19.379550Z",
     "iopub.status.busy": "2025-07-22T16:38:19.379237Z",
     "iopub.status.idle": "2025-07-22T16:38:19.385095Z",
     "shell.execute_reply": "2025-07-22T16:38:19.384241Z"
    },
    "papermill": {
     "duration": 0.015374,
     "end_time": "2025-07-22T16:38:19.386418",
     "exception": false,
     "start_time": "2025-07-22T16:38:19.371044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel1(nn.Module) :\n",
    "    def __init__(self, vocab_sz, n_hidden) :\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        h = F.relu(self.h_h(self.i_h(x[:, 0])))\n",
    "        h = F.relu(self.h_h(h + self.i_h(x[:, 1])))\n",
    "        h = F.relu(self.h_h(h + self.i_h(x[:, 2])))\n",
    "        return self.h_o(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2168393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:19.402325Z",
     "iopub.status.busy": "2025-07-22T16:38:19.402043Z",
     "iopub.status.idle": "2025-07-22T16:38:22.092285Z",
     "shell.execute_reply": "2025-07-22T16:38:22.091199Z"
    },
    "papermill": {
     "duration": 2.700006,
     "end_time": "2025-07-22T16:38:22.093815",
     "exception": false,
     "start_time": "2025-07-22T16:38:19.393809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 - Train Loss: 1.7328, Valid Loss: 1.7726, Accuracy: 0.3601\n",
      "Epoch 2/4 - Train Loss: 1.4059, Valid Loss: 1.7477, Accuracy: 0.4207\n",
      "Epoch 3/4 - Train Loss: 1.3545, Valid Loss: 1.8860, Accuracy: 0.3551\n",
      "Epoch 4/4 - Train Loss: 1.3384, Valid Loss: 1.8298, Accuracy: 0.3601\n"
     ]
    }
   ],
   "source": [
    "model = LMModel1(len(vocab), 64).to(device)\n",
    "loss_func = F.cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 4\n",
    "\n",
    "for epoch in range(n_epochs) :\n",
    "    model.train()\n",
    "    total_train_loss, train_count = 0.0, 0\n",
    "    for xb, yb in train_dl :\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * xb.size(0)\n",
    "        train_count += xb.size(0)\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_count\n",
    "\n",
    "    model.eval()\n",
    "    total_valid_loss, valid_count, correct = 0.0, 0, 0\n",
    "    with torch.no_grad() :\n",
    "        for xb, yb in valid_dl :\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            total_valid_loss += loss.item() * xb.size(0)\n",
    "            predicted = preds.argmax(dim=1)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "            valid_count += yb.size(0)\n",
    "\n",
    "    avg_valid_loss = total_valid_loss / valid_count\n",
    "    acc = correct / valid_count\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}, Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ecd37",
   "metadata": {
    "papermill": {
     "duration": 0.008469,
     "end_time": "2025-07-22T16:38:22.112246",
     "exception": false,
     "start_time": "2025-07-22T16:38:22.103777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Not particularly impressive. First, let's rewrite the same model in a rolled way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4880f3",
   "metadata": {
    "papermill": {
     "duration": 0.007283,
     "end_time": "2025-07-22T16:38:22.127162",
     "exception": false,
     "start_time": "2025-07-22T16:38:22.119879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Rolled RNN with no inter-sequence memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c55f3483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:22.143847Z",
     "iopub.status.busy": "2025-07-22T16:38:22.143488Z",
     "iopub.status.idle": "2025-07-22T16:38:22.149118Z",
     "shell.execute_reply": "2025-07-22T16:38:22.148305Z"
    },
    "papermill": {
     "duration": 0.015608,
     "end_time": "2025-07-22T16:38:22.150410",
     "exception": false,
     "start_time": "2025-07-22T16:38:22.134802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel2(nn.Module) :\n",
    "    def __init__(self, vocab_sz, n_hidden) :\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        h = 0\n",
    "        for i in range(3) :\n",
    "            h = F.relu(self.h_h(h + self.i_h(x[:, i])))\n",
    "        return self.h_o(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83572df3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:22.233110Z",
     "iopub.status.busy": "2025-07-22T16:38:22.232796Z",
     "iopub.status.idle": "2025-07-22T16:38:24.926586Z",
     "shell.execute_reply": "2025-07-22T16:38:24.925586Z"
    },
    "papermill": {
     "duration": 2.70412,
     "end_time": "2025-07-22T16:38:24.928128",
     "exception": false,
     "start_time": "2025-07-22T16:38:22.224008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 - Train Loss: 1.7565, Valid Loss: 1.7618, Accuracy: 0.4733\n",
      "Epoch 2/4 - Train Loss: 1.4184, Valid Loss: 1.8412, Accuracy: 0.3630\n",
      "Epoch 3/4 - Train Loss: 1.3678, Valid Loss: 1.7521, Accuracy: 0.4271\n",
      "Epoch 4/4 - Train Loss: 1.3440, Valid Loss: 1.7816, Accuracy: 0.4186\n"
     ]
    }
   ],
   "source": [
    "model = LMModel2(len(vocab), 64).to(device)\n",
    "loss_func = F.cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 4\n",
    "\n",
    "for epoch in range(n_epochs) :\n",
    "    model.train()\n",
    "    total_train_loss, train_count = 0.0, 0\n",
    "    for xb, yb in train_dl :\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * xb.size(0)\n",
    "        train_count += xb.size(0)\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_count\n",
    "\n",
    "    model.eval()\n",
    "    total_valid_loss, valid_count, correct = 0.0, 0, 0\n",
    "    with torch.no_grad() :\n",
    "        for xb, yb in valid_dl :\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            total_valid_loss += loss.item() * xb.size(0)\n",
    "            predicted = preds.argmax(dim=1)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "            valid_count += yb.size(0)\n",
    "\n",
    "    avg_valid_loss = total_valid_loss / valid_count\n",
    "    acc = correct / valid_count\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}, Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4f12e",
   "metadata": {
    "papermill": {
     "duration": 0.007589,
     "end_time": "2025-07-22T16:38:24.944103",
     "exception": false,
     "start_time": "2025-07-22T16:38:24.936514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The result is the same which is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a6fda",
   "metadata": {
    "papermill": {
     "duration": 0.007418,
     "end_time": "2025-07-22T16:38:24.959299",
     "exception": false,
     "start_time": "2025-07-22T16:38:24.951881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Remembering the hidden state between sequences\n",
    "Now, let us translate the hidden state between sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30a3e445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:24.975870Z",
     "iopub.status.busy": "2025-07-22T16:38:24.975534Z",
     "iopub.status.idle": "2025-07-22T16:38:24.981634Z",
     "shell.execute_reply": "2025-07-22T16:38:24.980833Z"
    },
    "papermill": {
     "duration": 0.016029,
     "end_time": "2025-07-22T16:38:24.983119",
     "exception": false,
     "start_time": "2025-07-22T16:38:24.967090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel3(nn.Module) :\n",
    "    def __init__(self, vocab_sz, n_hidden) :\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h = 0\n",
    "\n",
    "    def forward(self, x) :\n",
    "        for i in range(3) :\n",
    "            self.h = F.relu(self.h_h(self.h + self.i_h(x[:, i])))\n",
    "        out = self.h_o(self.h)\n",
    "        self.h = self.h.detach()\n",
    "        return out\n",
    "\n",
    "    def reset(self) : self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c60c91d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:25.000001Z",
     "iopub.status.busy": "2025-07-22T16:38:24.999647Z",
     "iopub.status.idle": "2025-07-22T16:38:25.005194Z",
     "shell.execute_reply": "2025-07-22T16:38:25.004316Z"
    },
    "papermill": {
     "duration": 0.015732,
     "end_time": "2025-07-22T16:38:25.006790",
     "exception": false,
     "start_time": "2025-07-22T16:38:24.991058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 64, 21031)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(seqs)//bs\n",
    "m, bs, len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be97f8ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:25.023903Z",
     "iopub.status.busy": "2025-07-22T16:38:25.023569Z",
     "iopub.status.idle": "2025-07-22T16:38:25.028416Z",
     "shell.execute_reply": "2025-07-22T16:38:25.027557Z"
    },
    "papermill": {
     "duration": 0.015069,
     "end_time": "2025-07-22T16:38:25.029891",
     "exception": false,
     "start_time": "2025-07-22T16:38:25.014822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_chunks(ds, bs) :\n",
    "    m = len(ds) // bs\n",
    "    new_ds = []\n",
    "    for i in range(m) :\n",
    "        for j in range(bs) :\n",
    "            new_ds.append(ds[i + m*j])\n",
    "    return new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d307c65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:25.047147Z",
     "iopub.status.busy": "2025-07-22T16:38:25.046835Z",
     "iopub.status.idle": "2025-07-22T16:38:25.055570Z",
     "shell.execute_reply": "2025-07-22T16:38:25.054701Z"
    },
    "papermill": {
     "duration": 0.019024,
     "end_time": "2025-07-22T16:38:25.057030",
     "exception": false,
     "start_time": "2025-07-22T16:38:25.038006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cut = int(len(seqs) * 0.8)\n",
    "\n",
    "train_ds = group_chunks(seqs[:cut], bs)\n",
    "valid_ds = group_chunks(seqs[cut:], bs)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=False, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d010053b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:25.074010Z",
     "iopub.status.busy": "2025-07-22T16:38:25.073670Z",
     "iopub.status.idle": "2025-07-22T16:38:30.784079Z",
     "shell.execute_reply": "2025-07-22T16:38:30.782938Z"
    },
    "papermill": {
     "duration": 5.720495,
     "end_time": "2025-07-22T16:38:30.785467",
     "exception": false,
     "start_time": "2025-07-22T16:38:25.064972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 1.5023, Valid Loss: 1.8441, Accuracy: 0.3969\n",
      "Epoch 2/10 - Train Loss: 1.1535, Valid Loss: 1.6308, Accuracy: 0.4618\n",
      "Epoch 3/10 - Train Loss: 1.0777, Valid Loss: 1.6461, Accuracy: 0.4995\n",
      "Epoch 4/10 - Train Loss: 1.0316, Valid Loss: 1.6676, Accuracy: 0.5476\n",
      "Epoch 5/10 - Train Loss: 0.9905, Valid Loss: 1.8342, Accuracy: 0.5695\n",
      "Epoch 6/10 - Train Loss: 0.9910, Valid Loss: 1.8305, Accuracy: 0.5656\n",
      "Epoch 7/10 - Train Loss: 0.9670, Valid Loss: 1.7401, Accuracy: 0.5683\n",
      "Epoch 8/10 - Train Loss: 0.9510, Valid Loss: 1.8490, Accuracy: 0.5531\n",
      "Epoch 9/10 - Train Loss: 0.9448, Valid Loss: 1.8022, Accuracy: 0.5666\n",
      "Epoch 10/10 - Train Loss: 0.9395, Valid Loss: 1.9025, Accuracy: 0.5779\n"
     ]
    }
   ],
   "source": [
    "model = LMModel3(len(vocab), 64).to(device)\n",
    "loss_func = F.cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs) :\n",
    "    model.train()\n",
    "    model.reset()  # Reset at start of training epoch\n",
    "    total_train_loss, train_count = 0.0, 0\n",
    "    for xb, yb in train_dl :\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * xb.size(0)\n",
    "        train_count += xb.size(0)\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_count\n",
    "\n",
    "    model.eval()\n",
    "    model.reset()  # Reset at start of validation\n",
    "    total_valid_loss, valid_count, correct = 0.0, 0, 0\n",
    "    with torch.no_grad() :\n",
    "        for xb, yb in valid_dl :\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            total_valid_loss += loss.item() * xb.size(0)\n",
    "            predicted = preds.argmax(dim=1)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "            valid_count += yb.size(0)\n",
    "\n",
    "    avg_valid_loss = total_valid_loss / valid_count\n",
    "    acc = correct / valid_count\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}, Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977996a",
   "metadata": {
    "papermill": {
     "duration": 0.009092,
     "end_time": "2025-07-22T16:38:30.804077",
     "exception": false,
     "start_time": "2025-07-22T16:38:30.794985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A bit better. Let's increase the length of sequences and predict not just the next token but all the tokens in-between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98606a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:30.822083Z",
     "iopub.status.busy": "2025-07-22T16:38:30.821758Z",
     "iopub.status.idle": "2025-07-22T16:38:30.899961Z",
     "shell.execute_reply": "2025-07-22T16:38:30.899089Z"
    },
    "papermill": {
     "duration": 0.089079,
     "end_time": "2025-07-22T16:38:30.901610",
     "exception": false,
     "start_time": "2025-07-22T16:38:30.812531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sl = 16\n",
    "seqs = [(torch.tensor(nums[i:i+sl]), torch.tensor(nums[i+1:i+sl+1]))\n",
    "        for i in range(0, len(nums)-sl-1, sl)]\n",
    "cut = int(len(seqs) * 0.8)\n",
    "\n",
    "train_ds = group_chunks(seqs[:cut], bs)\n",
    "valid_ds = group_chunks(seqs[cut:], bs)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=False, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "082016bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:30.919862Z",
     "iopub.status.busy": "2025-07-22T16:38:30.919541Z",
     "iopub.status.idle": "2025-07-22T16:38:30.926270Z",
     "shell.execute_reply": "2025-07-22T16:38:30.925597Z"
    },
    "papermill": {
     "duration": 0.017399,
     "end_time": "2025-07-22T16:38:30.927538",
     "exception": false,
     "start_time": "2025-07-22T16:38:30.910139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['one',\n",
       "  '.',\n",
       "  'two',\n",
       "  '.',\n",
       "  'three',\n",
       "  '.',\n",
       "  'four',\n",
       "  '.',\n",
       "  'five',\n",
       "  '.',\n",
       "  'six',\n",
       "  '.',\n",
       "  'seven',\n",
       "  '.',\n",
       "  'eight',\n",
       "  '.'],\n",
       " ['.',\n",
       "  'two',\n",
       "  '.',\n",
       "  'three',\n",
       "  '.',\n",
       "  'four',\n",
       "  '.',\n",
       "  'five',\n",
       "  '.',\n",
       "  'six',\n",
       "  '.',\n",
       "  'seven',\n",
       "  '.',\n",
       "  'eight',\n",
       "  '.',\n",
       "  'nine']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[vocab[o] for o in s] for s in seqs[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452c81a",
   "metadata": {
    "papermill": {
     "duration": 0.008348,
     "end_time": "2025-07-22T16:38:30.944975",
     "exception": false,
     "start_time": "2025-07-22T16:38:30.936627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keeping predictions of each token, not just the last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1930f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:30.963079Z",
     "iopub.status.busy": "2025-07-22T16:38:30.962780Z",
     "iopub.status.idle": "2025-07-22T16:38:30.968905Z",
     "shell.execute_reply": "2025-07-22T16:38:30.968128Z"
    },
    "papermill": {
     "duration": 0.016788,
     "end_time": "2025-07-22T16:38:30.970109",
     "exception": false,
     "start_time": "2025-07-22T16:38:30.953321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel4(nn.Module) :\n",
    "    def __init__(self, vocab_sz, n_hidden) :\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h = 0\n",
    "\n",
    "    def forward(self, x) :\n",
    "        outs = []\n",
    "        for i in range(sl) :\n",
    "            self.h = F.relu(self.h_h(self.h + self.i_h(x[:, i])))\n",
    "            outs.append(self.h_o(self.h))\n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1)\n",
    "\n",
    "    def reset(self) :\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56fdf227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:30.988488Z",
     "iopub.status.busy": "2025-07-22T16:38:30.988190Z",
     "iopub.status.idle": "2025-07-22T16:38:37.428714Z",
     "shell.execute_reply": "2025-07-22T16:38:37.427731Z"
    },
    "papermill": {
     "duration": 6.451699,
     "end_time": "2025-07-22T16:38:37.430312",
     "exception": false,
     "start_time": "2025-07-22T16:38:30.978613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Train Loss: 1.8517, Valid Loss: 1.8244, Accuracy: 0.4530\n",
      "Epoch 2/15 - Train Loss: 1.4244, Valid Loss: 1.9519, Accuracy: 0.4695\n",
      "Epoch 3/15 - Train Loss: 1.2804, Valid Loss: 1.8565, Accuracy: 0.5285\n",
      "Epoch 4/15 - Train Loss: 1.1383, Valid Loss: 1.8024, Accuracy: 0.5619\n",
      "Epoch 5/15 - Train Loss: 0.9835, Valid Loss: 1.9948, Accuracy: 0.6082\n",
      "Epoch 6/15 - Train Loss: 0.8950, Valid Loss: 1.9774, Accuracy: 0.6244\n",
      "Epoch 7/15 - Train Loss: 0.8068, Valid Loss: 2.0698, Accuracy: 0.6212\n",
      "Epoch 8/15 - Train Loss: 0.7745, Valid Loss: 1.9909, Accuracy: 0.6497\n",
      "Epoch 9/15 - Train Loss: 0.7305, Valid Loss: 2.1343, Accuracy: 0.6559\n",
      "Epoch 10/15 - Train Loss: 0.6878, Valid Loss: 2.0868, Accuracy: 0.6768\n",
      "Epoch 11/15 - Train Loss: 0.6328, Valid Loss: 2.1290, Accuracy: 0.6842\n",
      "Epoch 12/15 - Train Loss: 0.6430, Valid Loss: 2.2555, Accuracy: 0.6459\n",
      "Epoch 13/15 - Train Loss: 0.5980, Valid Loss: 2.1459, Accuracy: 0.6689\n",
      "Epoch 14/15 - Train Loss: 0.5504, Valid Loss: 2.4222, Accuracy: 0.6951\n",
      "Epoch 15/15 - Train Loss: 0.5442, Valid Loss: 1.9935, Accuracy: 0.6588\n"
     ]
    }
   ],
   "source": [
    "model = LMModel4(len(vocab), 64).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "def loss_func(inp, targ) :\n",
    "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))\n",
    "\n",
    "n_epochs = 15\n",
    "\n",
    "for epoch in range(n_epochs) :\n",
    "    model.train()\n",
    "    model.reset()  # Reset at start of training epoch\n",
    "    total_train_loss, train_count = 0.0, 0\n",
    "    for xb, yb in train_dl :\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * xb.numel()\n",
    "        train_count += xb.numel()\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_count\n",
    "\n",
    "    model.eval()\n",
    "    model.reset()  # Reset at start of validation\n",
    "    total_valid_loss, valid_count, correct = 0.0, 0, 0\n",
    "    with torch.no_grad() :\n",
    "        for xb, yb in valid_dl :\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            total_valid_loss += loss.item() * xb.numel()\n",
    "            predicted = preds.argmax(dim=-1)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "            valid_count += yb.numel()\n",
    "\n",
    "    avg_valid_loss = total_valid_loss / valid_count\n",
    "    acc = correct / valid_count\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}, Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a619c",
   "metadata": {
    "papermill": {
     "duration": 0.012566,
     "end_time": "2025-07-22T16:38:37.455897",
     "exception": false,
     "start_time": "2025-07-22T16:38:37.443331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The accuracy is around 60%. Let us stack several layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176408f3",
   "metadata": {
    "papermill": {
     "duration": 0.010859,
     "end_time": "2025-07-22T16:38:37.476103",
     "exception": false,
     "start_time": "2025-07-22T16:38:37.465244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Implementing multi-layer RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce9adba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:37.496197Z",
     "iopub.status.busy": "2025-07-22T16:38:37.495378Z",
     "iopub.status.idle": "2025-07-22T16:38:37.504458Z",
     "shell.execute_reply": "2025-07-22T16:38:37.503765Z"
    },
    "papermill": {
     "duration": 0.020714,
     "end_time": "2025-07-22T16:38:37.505982",
     "exception": false,
     "start_time": "2025-07-22T16:38:37.485268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel5(nn.Module) :\n",
    "    def __init__(self, vocab_sz, n_hidden, num_layers) :\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.i_h = nn.ModuleList([nn.Embedding(vocab_sz, n_hidden)])\n",
    "        self.h_h = nn.ModuleList([nn.Linear(n_hidden, n_hidden)])\n",
    "        for _ in range(1, num_layers) :\n",
    "            self.i_h.append(nn.Linear(n_hidden, n_hidden))\n",
    "            self.h_h.append(nn.Linear(n_hidden, n_hidden))\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h = [torch.zeros(bs, n_hidden) for _ in range(num_layers)]\n",
    "\n",
    "    def forward(self, x) :\n",
    "        outs = []\n",
    "        for i in range(sl) :\n",
    "            i_t = self.i_h[0](x[:, i])\n",
    "            self.h[0] = F.relu(self.h_h[0](self.h[0]) + i_t)\n",
    "            for n in range(1, self.num_layers) :\n",
    "                hn_in = self.i_h[n](self.h[n-1])\n",
    "                self.h[n] = F.relu(self.h_h[n](self.h[n]) + hn_in)\n",
    "            outs.append(self.h_o(self.h[-1]))\n",
    "        self.h = [h.detach() for h in self.h]\n",
    "        return torch.stack(outs, dim=1)\n",
    "\n",
    "    def reset(self) :\n",
    "        self.h = [h.detach().zero_() for h in self.h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08317c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:37.526118Z",
     "iopub.status.busy": "2025-07-22T16:38:37.525785Z",
     "iopub.status.idle": "2025-07-22T16:38:47.081500Z",
     "shell.execute_reply": "2025-07-22T16:38:47.080349Z"
    },
    "papermill": {
     "duration": 9.567792,
     "end_time": "2025-07-22T16:38:47.083225",
     "exception": false,
     "start_time": "2025-07-22T16:38:37.515433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Train Loss: 1.8761, Valid Loss: 1.7912, Accuracy: 0.4659\n",
      "Epoch 2/15 - Train Loss: 1.3987, Valid Loss: 1.7455, Accuracy: 0.4932\n",
      "Epoch 3/15 - Train Loss: 1.1992, Valid Loss: 1.7987, Accuracy: 0.5452\n",
      "Epoch 4/15 - Train Loss: 0.9913, Valid Loss: 1.8842, Accuracy: 0.5468\n",
      "Epoch 5/15 - Train Loss: 0.8194, Valid Loss: 1.8764, Accuracy: 0.6131\n",
      "Epoch 6/15 - Train Loss: 0.7007, Valid Loss: 2.1711, Accuracy: 0.6082\n",
      "Epoch 7/15 - Train Loss: 0.5846, Valid Loss: 2.1935, Accuracy: 0.6261\n",
      "Epoch 8/15 - Train Loss: 0.5048, Valid Loss: 2.2806, Accuracy: 0.6772\n",
      "Epoch 9/15 - Train Loss: 0.4831, Valid Loss: 2.0081, Accuracy: 0.6990\n",
      "Epoch 10/15 - Train Loss: 0.3640, Valid Loss: 2.3589, Accuracy: 0.7424\n",
      "Epoch 11/15 - Train Loss: 0.3089, Valid Loss: 2.4489, Accuracy: 0.7367\n",
      "Epoch 12/15 - Train Loss: 0.3052, Valid Loss: 2.3807, Accuracy: 0.7336\n",
      "Epoch 13/15 - Train Loss: 0.2520, Valid Loss: 2.2906, Accuracy: 0.7096\n",
      "Epoch 14/15 - Train Loss: 0.2530, Valid Loss: 2.4756, Accuracy: 0.7558\n",
      "Epoch 15/15 - Train Loss: 0.1887, Valid Loss: 2.6199, Accuracy: 0.7395\n"
     ]
    }
   ],
   "source": [
    "model = LMModel5(len(vocab), 64, 2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "def loss_func(inp, targ) :\n",
    "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))\n",
    "\n",
    "n_epochs = 15\n",
    "\n",
    "for epoch in range(n_epochs) :\n",
    "    model.train()\n",
    "    model.reset()  # Reset at start of training epoch\n",
    "    total_train_loss, train_count = 0.0, 0\n",
    "    for xb, yb in train_dl :\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * xb.numel()\n",
    "        train_count += xb.numel()\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_count\n",
    "\n",
    "    model.eval()\n",
    "    model.reset()  # Reset at start of validation\n",
    "    total_valid_loss, valid_count, correct = 0.0, 0, 0\n",
    "    with torch.no_grad() :\n",
    "        for xb, yb in valid_dl :\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            total_valid_loss += loss.item() * xb.numel()\n",
    "            predicted = preds.argmax(dim=-1)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "            valid_count += yb.numel()\n",
    "\n",
    "    avg_valid_loss = total_valid_loss / valid_count\n",
    "    acc = correct / valid_count\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}, Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d330c2f",
   "metadata": {
    "papermill": {
     "duration": 0.009677,
     "end_time": "2025-07-22T16:38:47.103231",
     "exception": false,
     "start_time": "2025-07-22T16:38:47.093554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The accuracy is higher but the model needs more regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a6e83b",
   "metadata": {
    "papermill": {
     "duration": 0.009411,
     "end_time": "2025-07-22T16:38:47.122359",
     "exception": false,
     "start_time": "2025-07-22T16:38:47.112948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Implementing multi-layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdc3ddda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:47.143039Z",
     "iopub.status.busy": "2025-07-22T16:38:47.142707Z",
     "iopub.status.idle": "2025-07-22T16:38:47.149122Z",
     "shell.execute_reply": "2025-07-22T16:38:47.148220Z"
    },
    "papermill": {
     "duration": 0.018492,
     "end_time": "2025-07-22T16:38:47.150568",
     "exception": false,
     "start_time": "2025-07-22T16:38:47.132076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module) :\n",
    "    def __init__(self, ni, nh) :\n",
    "        super().__init__()\n",
    "        \n",
    "        # Combining 4 matrix multiplications into 2\n",
    "        self.ih = nn.Linear(ni, 4*nh)\n",
    "        self.hh = nn.Linear(nh, 4*nh)\n",
    "\n",
    "    def forward(self, x, state) :\n",
    "        h, c = state\n",
    "        # One big multiplication for all the gates\n",
    "        gates = (self.ih(x) + self.hh(h)).chunk(4, 1)\n",
    "        ingate, forgetgate, outgate = map(torch.sigmoid, gates[:3])\n",
    "        cellgate = torch.tanh(gates[3])\n",
    "\n",
    "        c = (forgetgate*c) + (ingate*cellgate)\n",
    "        h = outgate * c.tanh()\n",
    "        return h, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20afadc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:47.171940Z",
     "iopub.status.busy": "2025-07-22T16:38:47.171217Z",
     "iopub.status.idle": "2025-07-22T16:38:47.179667Z",
     "shell.execute_reply": "2025-07-22T16:38:47.178748Z"
    },
    "papermill": {
     "duration": 0.020708,
     "end_time": "2025-07-22T16:38:47.181200",
     "exception": false,
     "start_time": "2025-07-22T16:38:47.160492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel6(nn.Module) :\n",
    "    def __init__(self, vocab_sz, n_hidden, n_lay) :\n",
    "        super().__init__()\n",
    "        self.ih = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.cells = nn.ModuleList([\n",
    "            LSTMCell(n_hidden, n_hidden) for _ in range(n_lay)\n",
    "        ])\n",
    "        self.out = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.state = [\n",
    "            (torch.zeros(bs, n_hidden),\n",
    "             torch.zeros(bs, n_hidden))\n",
    "            for _ in range(n_lay)\n",
    "        ]\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        embedded = self.ih(x)  # [bs, sl, n_hidden]\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(sl) :\n",
    "            inp = embedded[:, t]\n",
    "\n",
    "            for i, cell in enumerate(self.cells) :\n",
    "                h, c = self.state[i]\n",
    "                h, (h, c) = cell(inp, (h, c))\n",
    "                self.state[i] = (h, c)\n",
    "                inp = h\n",
    "\n",
    "            outputs.append(self.out(inp))\n",
    "\n",
    "        self.state = [(h.detach(), c.detach()) for h, c in self.state]\n",
    "\n",
    "        return torch.stack(outputs, dim=1)  # [bs, sl, vocab_sz]\n",
    "\n",
    "    def reset(self) :\n",
    "        self.state = [\n",
    "            (h.detach().zero_(), c.detach().zero_())\n",
    "            for (h, c) in self.state\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "952e1372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:38:47.202513Z",
     "iopub.status.busy": "2025-07-22T16:38:47.202245Z",
     "iopub.status.idle": "2025-07-22T16:39:12.216266Z",
     "shell.execute_reply": "2025-07-22T16:39:12.215198Z"
    },
    "papermill": {
     "duration": 25.026583,
     "end_time": "2025-07-22T16:39:12.217759",
     "exception": false,
     "start_time": "2025-07-22T16:38:47.191176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Train Loss: 1.8802, Valid Loss: 1.7954, Accuracy: 0.3247\n",
      "Epoch 2/15 - Train Loss: 1.3469, Valid Loss: 1.8920, Accuracy: 0.3837\n",
      "Epoch 3/15 - Train Loss: 1.1755, Valid Loss: 2.0014, Accuracy: 0.4937\n",
      "Epoch 4/15 - Train Loss: 1.0609, Valid Loss: 1.9211, Accuracy: 0.5290\n",
      "Epoch 5/15 - Train Loss: 0.9369, Valid Loss: 1.9311, Accuracy: 0.5703\n",
      "Epoch 6/15 - Train Loss: 0.7917, Valid Loss: 1.8632, Accuracy: 0.6178\n",
      "Epoch 7/15 - Train Loss: 0.6542, Valid Loss: 1.7285, Accuracy: 0.6795\n",
      "Epoch 8/15 - Train Loss: 0.4961, Valid Loss: 1.6021, Accuracy: 0.6965\n",
      "Epoch 9/15 - Train Loss: 0.3598, Valid Loss: 1.7341, Accuracy: 0.7048\n",
      "Epoch 10/15 - Train Loss: 0.2724, Valid Loss: 1.5876, Accuracy: 0.7143\n",
      "Epoch 11/15 - Train Loss: 0.2034, Valid Loss: 1.5857, Accuracy: 0.7818\n",
      "Epoch 12/15 - Train Loss: 0.1524, Valid Loss: 1.4648, Accuracy: 0.7882\n",
      "Epoch 13/15 - Train Loss: 0.1002, Valid Loss: 1.4923, Accuracy: 0.7961\n",
      "Epoch 14/15 - Train Loss: 0.0760, Valid Loss: 1.5252, Accuracy: 0.8009\n",
      "Epoch 15/15 - Train Loss: 0.0581, Valid Loss: 1.2857, Accuracy: 0.8029\n"
     ]
    }
   ],
   "source": [
    "model = LMModel6(len(vocab), 64, 2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "def loss_func(inp, targ) :\n",
    "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))\n",
    "\n",
    "n_epochs = 15\n",
    "\n",
    "for epoch in range(n_epochs) :\n",
    "    model.train()\n",
    "    model.reset()  # Reset at start of training epoch\n",
    "    total_train_loss, train_count = 0.0, 0\n",
    "    for xb, yb in train_dl :\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * xb.numel()\n",
    "        train_count += xb.numel()\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_count\n",
    "\n",
    "    model.eval()\n",
    "    model.reset()  # Reset at start of validation\n",
    "    total_valid_loss, valid_count, correct = 0.0, 0, 0\n",
    "    with torch.no_grad() :\n",
    "        for xb, yb in valid_dl :\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            total_valid_loss += loss.item() * xb.numel()\n",
    "            predicted = preds.argmax(dim=-1)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "            valid_count += yb.numel()\n",
    "\n",
    "    avg_valid_loss = total_valid_loss / valid_count\n",
    "    acc = correct / valid_count\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}, Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42dd7b",
   "metadata": {
    "papermill": {
     "duration": 0.01022,
     "end_time": "2025-07-22T16:39:12.239129",
     "exception": false,
     "start_time": "2025-07-22T16:39:12.228909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the accuracy is over 80%, but we still need to regularize the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ce29d",
   "metadata": {
    "papermill": {
     "duration": 0.010262,
     "end_time": "2025-07-22T16:39:12.259891",
     "exception": false,
     "start_time": "2025-07-22T16:39:12.249629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Adding regularization techniques:\n",
    "* Dropout\n",
    "* Activation Regularization (AR)\n",
    "* Temporal Activation Regularization (TAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a528c3be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:39:12.282606Z",
     "iopub.status.busy": "2025-07-22T16:39:12.281940Z",
     "iopub.status.idle": "2025-07-22T16:39:12.286894Z",
     "shell.execute_reply": "2025-07-22T16:39:12.286163Z"
    },
    "papermill": {
     "duration": 0.017668,
     "end_time": "2025-07-22T16:39:12.288055",
     "exception": false,
     "start_time": "2025-07-22T16:39:12.270387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDropout(nn.Module) :\n",
    "    def __init__(self, p) :\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        if not self.training: return x\n",
    "        mask = x.new(*x.shape).bernoulli_(1-self.p)\n",
    "        return x * mask.div_(1-self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "405557f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:39:12.310012Z",
     "iopub.status.busy": "2025-07-22T16:39:12.309650Z",
     "iopub.status.idle": "2025-07-22T16:39:12.315474Z",
     "shell.execute_reply": "2025-07-22T16:39:12.314579Z"
    },
    "papermill": {
     "duration": 0.018594,
     "end_time": "2025-07-22T16:39:12.316911",
     "exception": false,
     "start_time": "2025-07-22T16:39:12.298317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyRNNRegularizer :\n",
    "    def __init__(self, alpha=2., beta=1.) :\n",
    "        self.alpha, self.beta = alpha, beta\n",
    "\n",
    "    def __call__(self, pred) :\n",
    "        # Skip regularization if pred is not a 3-tuple\n",
    "        if not (isinstance(pred, (tuple, list)) and len(pred) == 3) :\n",
    "            return 0.0\n",
    "\n",
    "        logits, raw, out = pred\n",
    "        ar_loss = self.alpha * out.pow(2).mean()\n",
    "        tar_loss = self.beta * (raw[:, 1:] - raw[:, :-1]).pow(2).mean()\n",
    "        \n",
    "        return ar_loss + tar_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71d5b159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:39:12.339668Z",
     "iopub.status.busy": "2025-07-22T16:39:12.339318Z",
     "iopub.status.idle": "2025-07-22T16:39:12.348641Z",
     "shell.execute_reply": "2025-07-22T16:39:12.347770Z"
    },
    "papermill": {
     "duration": 0.022477,
     "end_time": "2025-07-22T16:39:12.350202",
     "exception": false,
     "start_time": "2025-07-22T16:39:12.327725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LMModel7(nn.Module) :\n",
    "    def __init__(self, vocab_sz, n_hidden, n_lay, p) :\n",
    "        super().__init__()\n",
    "        self.ih = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.cells = nn.ModuleList([\n",
    "            LSTMCell(n_hidden, n_hidden) for _ in range(n_lay)\n",
    "        ])\n",
    "        self.drop = MyDropout(p)\n",
    "        self.out = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.out.weight = self.ih.weight\n",
    "        self.state = [\n",
    "            (torch.zeros(bs, n_hidden),\n",
    "             torch.zeros(bs, n_hidden))\n",
    "            for _ in range(n_lay)\n",
    "        ]\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        embedded = self.ih(x)  # [bs, sl, n_hidden]\n",
    "        raw = []\n",
    "\n",
    "        for t in range(sl) :\n",
    "            inp = embedded[:, t]\n",
    "\n",
    "            for i, cell in enumerate(self.cells) :\n",
    "                h, c = self.state[i]\n",
    "                h, (h, c) = cell(inp, (h, c))\n",
    "                self.state[i] = (h, c)\n",
    "                inp = h\n",
    "\n",
    "            raw.append(inp)\n",
    "\n",
    "        raw = torch.stack(raw, dim=1)\n",
    "        out = self.drop(raw)\n",
    "        logits = self.out(out)\n",
    "        \n",
    "        self.state = [(h.detach(), c.detach()) for h, c in self.state] \n",
    "\n",
    "        if self.training :\n",
    "            return logits, raw, out\n",
    "        else :\n",
    "            return logits\n",
    "\n",
    "    def reset(self) :\n",
    "        self.state = [\n",
    "            (h.detach().zero_(), c.detach().zero_())\n",
    "            for (h, c) in self.state\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6e2fb84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T16:39:12.373235Z",
     "iopub.status.busy": "2025-07-22T16:39:12.372929Z",
     "iopub.status.idle": "2025-07-22T16:39:45.543257Z",
     "shell.execute_reply": "2025-07-22T16:39:45.542364Z"
    },
    "papermill": {
     "duration": 33.183197,
     "end_time": "2025-07-22T16:39:45.544598",
     "exception": false,
     "start_time": "2025-07-22T16:39:12.361401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Train Loss: 1.9306, Valid Loss: 1.6843, Accuracy: 0.5283\n",
      "Epoch 2/15 - Train Loss: 1.0089, Valid Loss: 1.0166, Accuracy: 0.6985\n",
      "Epoch 3/15 - Train Loss: 0.5120, Valid Loss: 0.6242, Accuracy: 0.8263\n",
      "Epoch 4/15 - Train Loss: 0.2701, Valid Loss: 0.5663, Accuracy: 0.8388\n",
      "Epoch 5/15 - Train Loss: 0.1885, Valid Loss: 0.5122, Accuracy: 0.8545\n",
      "Epoch 6/15 - Train Loss: 0.1476, Valid Loss: 0.5333, Accuracy: 0.8486\n",
      "Epoch 7/15 - Train Loss: 0.1254, Valid Loss: 0.4981, Accuracy: 0.8538\n",
      "Epoch 8/15 - Train Loss: 0.1122, Valid Loss: 0.5444, Accuracy: 0.8421\n",
      "Epoch 9/15 - Train Loss: 0.1024, Valid Loss: 0.5230, Accuracy: 0.8494\n",
      "Epoch 10/15 - Train Loss: 0.0929, Valid Loss: 0.5928, Accuracy: 0.8445\n",
      "Epoch 11/15 - Train Loss: 0.0869, Valid Loss: 0.5411, Accuracy: 0.8425\n",
      "Epoch 12/15 - Train Loss: 0.0842, Valid Loss: 0.5585, Accuracy: 0.8490\n",
      "Epoch 13/15 - Train Loss: 0.0803, Valid Loss: 0.5226, Accuracy: 0.8464\n",
      "Epoch 14/15 - Train Loss: 0.0796, Valid Loss: 0.6197, Accuracy: 0.8416\n",
      "Epoch 15/15 - Train Loss: 0.0723, Valid Loss: 0.5675, Accuracy: 0.8444\n"
     ]
    }
   ],
   "source": [
    "# learn = Learner(dls, LMModel7(len(vocab), 64, 3, 0.5),\n",
    "#                 loss_func=loss_func2, metrics=accuracy,\n",
    "#                 cbs=[ModelResetter, MyRNNRegularizer()])\n",
    "# learn.fit_one_cycle(15, 1e-2, wd=0.1)\n",
    "\n",
    "model = LMModel7(len(vocab), 64, 3, 0.5).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "regularizer = MyRNNRegularizer(alpha=2., beta=1.)\n",
    "\n",
    "def loss_func(inp, targ) :\n",
    "    if isinstance(inp, tuple) :\n",
    "        logits = inp[0]\n",
    "    else :\n",
    "        logits = inp\n",
    "    return F.cross_entropy(logits.view(-1, len(vocab)), targ.view(-1))\n",
    "\n",
    "n_epochs = 15\n",
    "\n",
    "for epoch in range(n_epochs) :\n",
    "    model.train()\n",
    "    model.reset()  # Reset at start of training epoch\n",
    "    total_train_loss, train_count = 0.0, 0\n",
    "    for xb, yb in train_dl :\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb) + regularizer(preds)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * xb.numel()\n",
    "        train_count += xb.numel()\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_count\n",
    "\n",
    "    model.eval()\n",
    "    model.reset()  # Reset at start of validation\n",
    "    total_valid_loss, valid_count, correct = 0.0, 0, 0\n",
    "    with torch.no_grad() :\n",
    "        for xb, yb in valid_dl :\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            total_valid_loss += loss.item() * xb.numel()\n",
    "            predicted = preds.argmax(dim=-1)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "            valid_count += yb.numel()\n",
    "\n",
    "    avg_valid_loss = total_valid_loss / valid_count\n",
    "    acc = correct / valid_count\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}, Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab575d",
   "metadata": {
    "papermill": {
     "duration": 0.010948,
     "end_time": "2025-07-22T16:39:45.567163",
     "exception": false,
     "start_time": "2025-07-22T16:39:45.556215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The accuracy is around 86% and the model is much more regularized."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 108.204902,
   "end_time": "2025-07-22T16:39:47.925635",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-22T16:37:59.720733",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
